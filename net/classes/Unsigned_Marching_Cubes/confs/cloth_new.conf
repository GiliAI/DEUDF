general {
    base_exp_dir = ./experiment/out_cloth_batch_new/
    recording = [
        ./,
        ./models
    ]
}

dataset {
    data_dir = data/batch_data/
}

train {
    learning_rate = 0.001
    max_iter = 40000
    max_iter_2 = 60000
    warm_up_end = 1000
    eval_num_points = 1000000
    df_filter = 0.01
    far = -1
    outlier = 0.002
    extra_points_rate = 1
    low_range = 1.1

    batch_size = 10000
    batch_size_step2 = 20000

    save_freq = 5000
    val_freq = 5000
    val_mesh_freq = 5000
    resolution = 128
    threshold = 0.01
    report_freq = 5000

    igr_weight = 0.1
    mask_weight = 0.0
    load_ckpt = none
}
evaluate {
    load_ckpt = ckpt_060000.pth
    use_vectorAdam = 1
    max_iter = 400
    normal_step = 300
    report_freq = 100
    max_batch = 100000
    export_grad_field = 1
    laplacian_weight = 2000
    max_dist_threshold = 1.5
    save_iter = 100
    learning_rate = 0.0005
    warm_up_end = 25
    resolution = 128
    threshold = 0.005
    use_exist_mesh = 0
    draw_slice = 0
    is_cut = 0
    region_rate = 20
    use_exist_mesh = 0
}
model {
    udf_network {
        d_in = 3
        d_hidden = 256
        n_layers = 8
        skip_in = [4]
        multires = 8
        bias = 0.5
        scale = 1.0
        geometric_init = True
        weight_norm = True
        d_out = 1
    }

}
